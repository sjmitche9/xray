# ğŸ§  Text-to-X-ray: Generating Chest X-rays from Radiology Reports with Diffusion Models

This project explores a novel direction in multimodal learning: generating realistic chest X-ray images directly from free-text radiology reports. By combining latent-space modeling with modern diffusion techniques, we build a pipeline that can reconstruct plausible medical images conditioned on clinical descriptions.

---

## ğŸš€ Project Goals

- Generate chest X-ray images from radiology reports using latent diffusion.
- Leverage pretrained medical language models (Bio_ClinicalBERT) and a variational autoencoder.
- Evaluate the feasibility of text-to-image generation for clinical education, simulation, and dataset augmentation.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml                     # Centralized training and path configuration
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ vae.py                          # Variational Autoencoder for image compression
â”‚   â”œâ”€â”€ text_to_latent.py              # MLP to map BERT embeddings to image latents
â”‚   â”œâ”€â”€ text_encoder.py                # Frozen Bio_ClinicalBERT wrapper
â”‚   â”œâ”€â”€ unet.py                        # Conditional U-Net for full image diffusion
â”‚   â”œâ”€â”€ diffusion.py                   # End-to-end diffusion model wrapper
â”‚   â””â”€â”€ latent_unet.py                 # Lightweight UNet for simplified latent training
â”‚
â”œâ”€â”€ scheduler/
â”‚   â””â”€â”€ ddpm_scheduler.py              # Beta schedule for DDPM diffusion
â”‚
â”œâ”€â”€ train_vae_model.py                 # Trains VAE on X-ray images
â”œâ”€â”€ train_text_to_latent.py           # Trains mapping from report embeddings to image latents
â”œâ”€â”€ train_diffusion_model.py          # Trains diffusion model to generate latents
â”‚
â”œâ”€â”€ preprocess_dataset.py             # Converts raw image/report pairs into disk chunks
â”œâ”€â”€ make_latent_dataset.py            # Precomputes latents and embeddings for fast training
â”œâ”€â”€ generate.py                        # Generates samples from a report prompt
â”‚
â”œâ”€â”€ requirements.txt                   # Dependencies
â”œâ”€â”€ README.md                          # You're here
```

---

## ğŸ§ª Workflow Overview

1. **Preprocess the Dataset**

2. **Train the Variational Autoencoder (VAE)**

3. **Generate Latent Dataset**

4. **Train Text-to-Latent Model**

5. **Train Latent Diffusion Model**

6. **Generate Image from Report**

---

## ğŸ“Œ Notes

- All configuration is handled through `config/config.yaml`.
- Chunked training allows scaling to large datasets on low-memory machines.
- Training and evaluation logs are managed via [Weights & Biases](https://wandb.ai/).

---

## ğŸ“š Citation & Credits

- MIMIC-CXR: Johnson A, Lungren M, Peng Y, Lu Z, Mark R, Berkowitz S, Horng S. MIMIC-CXR-JPG - chest radiographs with structured labels (version 2.1. 0). PhysioNet. 2024. RRID:SCR_007345. Available from: https://doi.org/10.13026/jsn5-t979
- Bio_ClinicalBERT: Alsentzer et al.
- DDPM: Ho et al. 2020

---

## ğŸ› ï¸ Future Work

- CLIPScore or radiology-specific generation metrics
- Mixed precision and multi-GPU support
- Zero-shot transfer from synthetic to real domains